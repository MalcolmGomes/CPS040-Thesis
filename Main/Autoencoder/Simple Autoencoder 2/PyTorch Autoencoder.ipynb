{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import datasets\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 183.676865\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 45.187099\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 42.488605\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 38.989422\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 37.602478\n",
      "====> Epoch: 0 Average loss: 45.2671\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 37.402729\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 34.094231\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 36.393234\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 35.329041\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 33.767498\n",
      "====> Epoch: 1 Average loss: 34.8616\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 33.174458\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 33.061054\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 34.152504\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 33.052860\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 34.183891\n",
      "====> Epoch: 2 Average loss: 33.0455\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 33.032677\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 31.276497\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 30.798950\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 33.598492\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 30.768045\n",
      "====> Epoch: 3 Average loss: 32.1883\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 31.744070\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 32.317257\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 31.286747\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 30.449802\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 32.253605\n",
      "====> Epoch: 4 Average loss: 31.6254\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 30.427490\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 30.359837\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 31.622990\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 31.984749\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 31.268511\n",
      "====> Epoch: 5 Average loss: 31.3139\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 30.284370\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 32.221291\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 31.119949\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 30.388073\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 32.043633\n",
      "====> Epoch: 6 Average loss: 31.0403\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 30.521250\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 30.403748\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 30.509127\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 32.068398\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 28.933823\n",
      "====> Epoch: 7 Average loss: 30.8684\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 31.702736\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 30.426323\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 30.908155\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 31.359673\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 30.072823\n",
      "====> Epoch: 8 Average loss: 30.7118\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 29.105972\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 31.185699\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 30.625431\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 29.578272\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 30.092827\n",
      "====> Epoch: 9 Average loss: 30.5351\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 30.569691\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 30.963316\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 31.450470\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 29.399740\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 31.465643\n",
      "====> Epoch: 10 Average loss: 30.4183\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 29.863323\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 31.702944\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 30.375435\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 30.614920\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 31.104290\n",
      "====> Epoch: 11 Average loss: 30.2947\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 30.635328\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 30.794292\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 29.629967\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 31.002506\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 31.834450\n",
      "====> Epoch: 12 Average loss: 30.1977\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 31.844101\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 30.275272\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 31.552971\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 29.969439\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 30.622873\n",
      "====> Epoch: 13 Average loss: 30.0987\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 31.345516\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 29.208092\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 30.981087\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 29.842527\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 29.471073\n",
      "====> Epoch: 14 Average loss: 30.0371\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 30.243219\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 31.257406\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 31.171150\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 29.725487\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 30.136295\n",
      "====> Epoch: 15 Average loss: 29.9561\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 29.823818\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 30.149372\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 30.137871\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 30.265120\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 29.313202\n",
      "====> Epoch: 16 Average loss: 29.8661\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 28.884960\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 31.226595\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 29.328125\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 29.933277\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 30.342678\n",
      "====> Epoch: 17 Average loss: 29.7951\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 29.012720\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 29.619055\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 29.710350\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 30.021046\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 29.863018\n",
      "====> Epoch: 18 Average loss: 29.7478\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 29.874859\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 30.452003\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 30.299290\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 29.744881\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 30.127144\n",
      "====> Epoch: 19 Average loss: 29.6725\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 28.768875\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 29.981377\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 29.071600\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 30.442604\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 29.223658\n",
      "====> Epoch: 20 Average loss: 29.6160\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 28.774736\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 29.855656\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 29.908728\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 28.142870\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 30.855984\n",
      "====> Epoch: 21 Average loss: 29.5557\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 30.027004\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 29.189833\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 30.409742\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 30.011763\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 29.479464\n",
      "====> Epoch: 22 Average loss: 29.5342\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 28.862682\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 29.603645\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 29.919056\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 29.246876\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 28.400059\n",
      "====> Epoch: 23 Average loss: 29.4679\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 28.521662\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 29.586288\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 29.827963\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 30.119339\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 29.191990\n",
      "====> Epoch: 24 Average loss: 29.4263\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 29.601412\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 29.614132\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 30.114256\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 28.678373\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 29.277655\n",
      "====> Epoch: 25 Average loss: 29.4014\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 29.223703\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 30.512798\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 30.992340\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 30.080948\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 28.460073\n",
      "====> Epoch: 26 Average loss: 29.3409\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 29.075253\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 30.167816\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 29.684668\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 29.438530\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 30.252964\n",
      "====> Epoch: 27 Average loss: 29.3262\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 30.173571\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 29.899376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 28.570789\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 30.629684\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 28.481743\n",
      "====> Epoch: 28 Average loss: 29.2502\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 30.174021\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 29.047501\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 29.471247\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 27.916105\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 29.007961\n",
      "====> Epoch: 29 Average loss: 29.2216\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 28.800220\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 27.507565\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 29.240309\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 29.175335\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 30.258394\n",
      "====> Epoch: 30 Average loss: 29.1814\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 28.845753\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 30.306904\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 30.310234\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 29.328053\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 30.955351\n",
      "====> Epoch: 31 Average loss: 29.1533\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 29.708889\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 28.837404\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 29.348190\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 30.232124\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 30.155548\n",
      "====> Epoch: 32 Average loss: 29.1453\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 28.670448\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 28.667286\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 29.636820\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 28.707829\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 28.313297\n",
      "====> Epoch: 33 Average loss: 29.0944\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 29.597460\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 27.679569\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 28.674189\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 28.385689\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 28.773445\n",
      "====> Epoch: 34 Average loss: 29.0724\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 27.588634\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 28.931160\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 29.197098\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 28.497370\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 27.963549\n",
      "====> Epoch: 35 Average loss: 29.0402\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 29.655521\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 29.513210\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 28.189310\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 28.676456\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 28.741024\n",
      "====> Epoch: 36 Average loss: 29.0023\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 28.686794\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 30.198118\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 29.464483\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 29.516449\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 29.056324\n",
      "====> Epoch: 37 Average loss: 28.9985\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 27.401661\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 28.769487\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 28.900211\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 29.288912\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 29.216015\n",
      "====> Epoch: 38 Average loss: 28.9716\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 29.760695\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 30.025116\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 28.369871\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 29.144932\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 28.063911\n",
      "====> Epoch: 39 Average loss: 28.9763\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 28.200905\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 28.624294\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 29.733606\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 27.760897\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 30.002163\n",
      "====> Epoch: 40 Average loss: 28.9288\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 30.367222\n",
      "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 28.727402\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 30.029181\n",
      "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 28.074276\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 28.604851\n",
      "====> Epoch: 41 Average loss: 28.9136\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 29.384274\n",
      "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 28.484774\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 30.677444\n",
      "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 27.208094\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 28.078875\n",
      "====> Epoch: 42 Average loss: 28.9082\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 28.949528\n",
      "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 29.348824\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 28.212967\n",
      "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 29.192564\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 29.343082\n",
      "====> Epoch: 43 Average loss: 28.8729\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 30.548641\n",
      "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 28.297812\n",
      "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 29.361843\n",
      "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 28.740314\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 28.024010\n",
      "====> Epoch: 44 Average loss: 28.8369\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 29.663700\n",
      "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 27.700720\n",
      "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 28.295982\n",
      "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 28.809099\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 27.204643\n",
      "====> Epoch: 45 Average loss: 28.8165\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 29.989813\n",
      "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 29.075899\n",
      "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 27.869171\n",
      "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 29.864220\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 27.507877\n",
      "====> Epoch: 46 Average loss: 28.8083\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 28.291771\n",
      "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 28.027695\n",
      "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 28.623220\n",
      "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 28.024055\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 29.082491\n",
      "====> Epoch: 47 Average loss: 28.8130\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 29.721653\n",
      "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 28.231972\n",
      "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 27.799713\n",
      "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 28.182587\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 29.024231\n",
      "====> Epoch: 48 Average loss: 28.7491\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 28.600986\n",
      "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 29.323658\n",
      "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 28.969570\n",
      "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 28.696594\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 29.373768\n",
      "====> Epoch: 49 Average loss: 28.7578\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 29.521917\n",
      "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 29.969128\n",
      "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 27.625694\n",
      "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 29.685692\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 28.687645\n",
      "====> Epoch: 50 Average loss: 28.7250\n",
      "Train Epoch: 51 [0/60000 (0%)]\tLoss: 28.692034\n",
      "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 29.528805\n",
      "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 30.039450\n",
      "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 27.993885\n",
      "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 29.527107\n",
      "====> Epoch: 51 Average loss: 28.7317\n",
      "Train Epoch: 52 [0/60000 (0%)]\tLoss: 28.649506\n",
      "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 29.624933\n",
      "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 28.503981\n",
      "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 28.841661\n",
      "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 29.232847\n",
      "====> Epoch: 52 Average loss: 28.7316\n",
      "Train Epoch: 53 [0/60000 (0%)]\tLoss: 28.543839\n",
      "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 28.950306\n",
      "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 28.468512\n",
      "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 28.463184\n",
      "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 28.829803\n",
      "====> Epoch: 53 Average loss: 28.6864\n",
      "Train Epoch: 54 [0/60000 (0%)]\tLoss: 29.982496\n",
      "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 27.482639\n",
      "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 28.893639\n",
      "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 29.390976\n",
      "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 28.382153\n",
      "====> Epoch: 54 Average loss: 28.6769\n",
      "Train Epoch: 55 [0/60000 (0%)]\tLoss: 28.415546\n",
      "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 29.624088\n",
      "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 29.628765\n",
      "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 28.648470\n",
      "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 28.594658\n",
      "====> Epoch: 55 Average loss: 28.6606\n",
      "Train Epoch: 56 [0/60000 (0%)]\tLoss: 28.512554\n",
      "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 28.951595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 29.247900\n",
      "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 29.587086\n",
      "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 27.743217\n",
      "====> Epoch: 56 Average loss: 28.6577\n",
      "Train Epoch: 57 [0/60000 (0%)]\tLoss: 29.061302\n",
      "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 28.293606\n",
      "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 29.515631\n",
      "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 27.644247\n",
      "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 28.170116\n",
      "====> Epoch: 57 Average loss: 28.6252\n",
      "Train Epoch: 58 [0/60000 (0%)]\tLoss: 27.568607\n",
      "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 28.772818\n",
      "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 28.738129\n",
      "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 28.690214\n",
      "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 29.499655\n",
      "====> Epoch: 58 Average loss: 28.6294\n",
      "Train Epoch: 59 [0/60000 (0%)]\tLoss: 28.631235\n",
      "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 28.710907\n",
      "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 28.085670\n",
      "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 27.647476\n",
      "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 28.379614\n",
      "====> Epoch: 59 Average loss: 28.6291\n",
      "Train Epoch: 60 [0/60000 (0%)]\tLoss: 27.910210\n",
      "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 29.400276\n",
      "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 27.087971\n",
      "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 29.248892\n",
      "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 29.088984\n",
      "====> Epoch: 60 Average loss: 28.5834\n",
      "Train Epoch: 61 [0/60000 (0%)]\tLoss: 28.667057\n",
      "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 27.174950\n",
      "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 27.776154\n",
      "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 27.472361\n",
      "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 29.019241\n",
      "====> Epoch: 61 Average loss: 28.5803\n",
      "Train Epoch: 62 [0/60000 (0%)]\tLoss: 28.933895\n",
      "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 29.020697\n",
      "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 28.435730\n",
      "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 28.736698\n",
      "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 28.191757\n",
      "====> Epoch: 62 Average loss: 28.5684\n",
      "Train Epoch: 63 [0/60000 (0%)]\tLoss: 29.180876\n",
      "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 27.948404\n",
      "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 28.151423\n",
      "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 29.500240\n",
      "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 28.607504\n",
      "====> Epoch: 63 Average loss: 28.5605\n",
      "Train Epoch: 64 [0/60000 (0%)]\tLoss: 28.380344\n",
      "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 29.069439\n",
      "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 29.278492\n",
      "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 28.815479\n",
      "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 28.820738\n",
      "====> Epoch: 64 Average loss: 28.5305\n",
      "Train Epoch: 65 [0/60000 (0%)]\tLoss: 26.534386\n",
      "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 28.254282\n",
      "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 28.281620\n",
      "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 29.295052\n",
      "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 27.685741\n",
      "====> Epoch: 65 Average loss: 28.5173\n",
      "Train Epoch: 66 [0/60000 (0%)]\tLoss: 29.427891\n",
      "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 29.533010\n",
      "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 28.195274\n",
      "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 29.046909\n",
      "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 27.111320\n",
      "====> Epoch: 66 Average loss: 28.5280\n",
      "Train Epoch: 67 [0/60000 (0%)]\tLoss: 29.665194\n",
      "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 29.282730\n",
      "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 29.569685\n",
      "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 28.184849\n",
      "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 29.203747\n",
      "====> Epoch: 67 Average loss: 28.4794\n",
      "Train Epoch: 68 [0/60000 (0%)]\tLoss: 27.472368\n",
      "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 28.922695\n",
      "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 28.383057\n",
      "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 27.626476\n",
      "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 29.162653\n",
      "====> Epoch: 68 Average loss: 28.5116\n",
      "Train Epoch: 69 [0/60000 (0%)]\tLoss: 26.854897\n",
      "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 27.823000\n",
      "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 27.919739\n",
      "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 29.008360\n",
      "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 28.874702\n",
      "====> Epoch: 69 Average loss: 28.4760\n",
      "Train Epoch: 70 [0/60000 (0%)]\tLoss: 27.846035\n",
      "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 27.932087\n",
      "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 27.958714\n",
      "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 27.376991\n",
      "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 29.781935\n",
      "====> Epoch: 70 Average loss: 28.4794\n",
      "Train Epoch: 71 [0/60000 (0%)]\tLoss: 27.730797\n",
      "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 27.876293\n",
      "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 29.055889\n",
      "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 27.435806\n",
      "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 29.557484\n",
      "====> Epoch: 71 Average loss: 28.4662\n",
      "Train Epoch: 72 [0/60000 (0%)]\tLoss: 28.049501\n",
      "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 27.806328\n",
      "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 27.853237\n",
      "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 30.619276\n",
      "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 27.722347\n",
      "====> Epoch: 72 Average loss: 28.4597\n",
      "Train Epoch: 73 [0/60000 (0%)]\tLoss: 27.437386\n",
      "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 29.236359\n",
      "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 28.374146\n",
      "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 28.104847\n",
      "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 27.535118\n",
      "====> Epoch: 73 Average loss: 28.4325\n",
      "Train Epoch: 74 [0/60000 (0%)]\tLoss: 28.136408\n",
      "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 27.987959\n",
      "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 27.981163\n",
      "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 29.353951\n",
      "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 27.054676\n",
      "====> Epoch: 74 Average loss: 28.4311\n",
      "Train Epoch: 75 [0/60000 (0%)]\tLoss: 27.708727\n",
      "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 27.389977\n",
      "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 28.825094\n",
      "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 27.195660\n",
      "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 28.183254\n",
      "====> Epoch: 75 Average loss: 28.3988\n",
      "Train Epoch: 76 [0/60000 (0%)]\tLoss: 28.133337\n",
      "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 27.663832\n",
      "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 28.221106\n",
      "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 28.338696\n",
      "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 28.767815\n",
      "====> Epoch: 76 Average loss: 28.4251\n",
      "Train Epoch: 77 [0/60000 (0%)]\tLoss: 28.980848\n",
      "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 28.029430\n",
      "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 28.560602\n",
      "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 27.654636\n",
      "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 27.899578\n",
      "====> Epoch: 77 Average loss: 28.4052\n",
      "Train Epoch: 78 [0/60000 (0%)]\tLoss: 28.598942\n",
      "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 28.391745\n",
      "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 28.972307\n",
      "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 28.275204\n",
      "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 28.264465\n",
      "====> Epoch: 78 Average loss: 28.3748\n",
      "Train Epoch: 79 [0/60000 (0%)]\tLoss: 29.945118\n",
      "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 28.195114\n",
      "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 29.817816\n",
      "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 28.335072\n",
      "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 28.346437\n",
      "====> Epoch: 79 Average loss: 28.3682\n",
      "Train Epoch: 80 [0/60000 (0%)]\tLoss: 28.784874\n",
      "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 29.700006\n",
      "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 27.062439\n",
      "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 28.919197\n",
      "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 29.232836\n",
      "====> Epoch: 80 Average loss: 28.3640\n",
      "Train Epoch: 81 [0/60000 (0%)]\tLoss: 29.264521\n",
      "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 28.761269\n",
      "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 27.194096\n",
      "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 28.750565\n",
      "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 29.088280\n",
      "====> Epoch: 81 Average loss: 28.3632\n",
      "Train Epoch: 82 [0/60000 (0%)]\tLoss: 28.400810\n",
      "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 27.321573\n",
      "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 29.167294\n",
      "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 28.425068\n",
      "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 28.799200\n",
      "====> Epoch: 82 Average loss: 28.3759\n",
      "Train Epoch: 83 [0/60000 (0%)]\tLoss: 26.687759\n",
      "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 29.209373\n",
      "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 28.775677\n",
      "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 28.008862\n",
      "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 27.838678\n",
      "====> Epoch: 83 Average loss: 28.3391\n",
      "Train Epoch: 84 [0/60000 (0%)]\tLoss: 29.426146\n",
      "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 28.360754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 27.627066\n",
      "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 28.466825\n",
      "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 27.368299\n",
      "====> Epoch: 84 Average loss: 28.3363\n",
      "Train Epoch: 85 [0/60000 (0%)]\tLoss: 29.110487\n",
      "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 26.514534\n",
      "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 28.300285\n",
      "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 29.096092\n",
      "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 27.519148\n",
      "====> Epoch: 85 Average loss: 28.3272\n",
      "Train Epoch: 86 [0/60000 (0%)]\tLoss: 29.128960\n",
      "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 28.217701\n",
      "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 28.445143\n",
      "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 28.766052\n",
      "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 28.905764\n",
      "====> Epoch: 86 Average loss: 28.3298\n",
      "Train Epoch: 87 [0/60000 (0%)]\tLoss: 28.341631\n",
      "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 26.555923\n",
      "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 28.292265\n",
      "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 28.520332\n",
      "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 30.028610\n",
      "====> Epoch: 87 Average loss: 28.3312\n",
      "Train Epoch: 88 [0/60000 (0%)]\tLoss: 29.118336\n",
      "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 26.846237\n",
      "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 28.539213\n",
      "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 28.565666\n",
      "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 28.600529\n",
      "====> Epoch: 88 Average loss: 28.3174\n",
      "Train Epoch: 89 [0/60000 (0%)]\tLoss: 28.118185\n",
      "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 28.715261\n",
      "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 27.513157\n",
      "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 27.220739\n",
      "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 27.625332\n",
      "====> Epoch: 89 Average loss: 28.2838\n",
      "Train Epoch: 90 [0/60000 (0%)]\tLoss: 28.182161\n",
      "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 28.048168\n",
      "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 26.718544\n",
      "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 27.800545\n",
      "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 27.937529\n",
      "====> Epoch: 90 Average loss: 28.2924\n",
      "Train Epoch: 91 [0/60000 (0%)]\tLoss: 29.408781\n",
      "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 28.408775\n",
      "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 29.460705\n",
      "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 28.479069\n",
      "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 28.429737\n",
      "====> Epoch: 91 Average loss: 28.2624\n",
      "Train Epoch: 92 [0/60000 (0%)]\tLoss: 26.722908\n",
      "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 28.306602\n",
      "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 27.118750\n",
      "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 27.716503\n",
      "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 27.662968\n",
      "====> Epoch: 92 Average loss: 28.2747\n",
      "Train Epoch: 93 [0/60000 (0%)]\tLoss: 28.949026\n",
      "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 28.314625\n",
      "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 28.276949\n",
      "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 28.343348\n",
      "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 28.584354\n",
      "====> Epoch: 93 Average loss: 28.2730\n",
      "Train Epoch: 94 [0/60000 (0%)]\tLoss: 28.804956\n",
      "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 28.164404\n",
      "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 29.134068\n",
      "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 28.626820\n",
      "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 28.605886\n",
      "====> Epoch: 94 Average loss: 28.2507\n",
      "Train Epoch: 95 [0/60000 (0%)]\tLoss: 29.147675\n",
      "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 28.607063\n",
      "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 28.071398\n",
      "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 27.230419\n",
      "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 28.079922\n",
      "====> Epoch: 95 Average loss: 28.2504\n",
      "Train Epoch: 96 [0/60000 (0%)]\tLoss: 28.619892\n",
      "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 28.561733\n",
      "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 28.098953\n",
      "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 28.469906\n",
      "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 27.772339\n",
      "====> Epoch: 96 Average loss: 28.2772\n",
      "Train Epoch: 97 [0/60000 (0%)]\tLoss: 26.551270\n",
      "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 28.822685\n",
      "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 28.796360\n",
      "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 28.432884\n",
      "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 28.054817\n",
      "====> Epoch: 97 Average loss: 28.2549\n",
      "Train Epoch: 98 [0/60000 (0%)]\tLoss: 28.002758\n",
      "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 28.036560\n",
      "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 27.717003\n",
      "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 28.318100\n",
      "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 28.005920\n",
      "====> Epoch: 98 Average loss: 28.2410\n",
      "Train Epoch: 99 [0/60000 (0%)]\tLoss: 30.174847\n",
      "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 27.370161\n",
      "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 28.511234\n",
      "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 28.868919\n",
      "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 27.331806\n",
      "====> Epoch: 99 Average loss: 28.2443\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./vae_img'):\n",
    "    os.mkdir('./vae_img')\n",
    "\n",
    "\n",
    "def to_img(x):\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = MNIST('./data', transform=img_transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc21 = nn.Linear(400, 20)\n",
    "        self.fc22 = nn.Linear(400, 20)\n",
    "        self.fc3 = nn.Linear(20, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        if torch.cuda.is_available():\n",
    "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "        else:\n",
    "            eps = torch.FloatTensor(std.size()).normal_()\n",
    "        eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return F.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "\n",
    "model = VAE()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "reconstruction_function = nn.MSELoss(size_average=False)\n",
    "\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    \"\"\"\n",
    "    recon_x: generating images\n",
    "    x: origin images\n",
    "    mu: latent mean\n",
    "    logvar: latent log variance\n",
    "    \"\"\"\n",
    "    BCE = reconstruction_function(recon_x, x)  # mse loss\n",
    "    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "    # KL divergence\n",
    "    return BCE + KLD\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(dataloader):\n",
    "        img, _ = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img = Variable(img)\n",
    "        if torch.cuda.is_available():\n",
    "            img = img.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(img)\n",
    "        loss = loss_function(recon_batch, img, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch,\n",
    "                batch_idx * len(img),\n",
    "                len(dataloader.dataset), 100. * batch_idx / len(dataloader),\n",
    "                loss.data / len(img)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "        epoch, train_loss / len(dataloader.dataset)))\n",
    "    if epoch % 10 == 0:\n",
    "        save = to_img(recon_batch.cpu().data)\n",
    "        save_image(save, './vae_img/image_{}.png'.format(epoch))\n",
    "\n",
    "torch.save(model.state_dict(), './vae.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use trained model to predict images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = \"D:\\\\University-Work\\CPS040\\Main\\CPS040-Thesis\\Main\\Autoencoder\\Simple Autoencoder 2\\\\vae_img\\\\\"\n",
    "min_img_size = 32\n",
    "trans = transforms.Compose([transforms.Resize(min_img_size),\n",
    "                                         transforms.CenterCrop(32),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                              std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# # Picture dataset.\n",
    "# classify_dataset = datasets.ImageFolder(root=IMG_PATH, transform=trans)\n",
    "# # Create custom random sampler class to iter over dataloader.\n",
    "# classify_loader = DataLoader(dataset=classify_dataset, batch_size=1, shuffle=True, num_workers=5)\n",
    "\n",
    "model = torch.load('./vae.pth')\n",
    "\n",
    "# if cuda is available, move the model to the GPU\n",
    "# if torch.cuda.is_available():\n",
    "#     model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'collections.OrderedDict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-8885a6a2c1c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./vae.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'collections.OrderedDict' object is not callable"
     ]
    }
   ],
   "source": [
    "def to_img(x):\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "dataset = MNIST('./data', transform=img_transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# for batch_idx, data in enumerate(dataloader):\n",
    "#     data\n",
    "\n",
    "img, _ = data\n",
    "img = img.view(img.size(0), -1)\n",
    "img = Variable(img)\n",
    "if torch.cuda.is_available():\n",
    "    img = img.cuda()\n",
    "    \n",
    "model = torch.load('./vae.pth')\n",
    "model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
